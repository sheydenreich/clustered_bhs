{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings as _warnings\n",
    "import os as _os\n",
    "from tempfile import mkdtemp\n",
    "import numpy as np\n",
    "\n",
    "class TemporaryDirectory(object):\n",
    "    \"\"\"Create and return a temporary directory.  This has the same\n",
    "    behavior as mkdtemp but can be used as a context manager.  For\n",
    "    example:\n",
    "\n",
    "        with TemporaryDirectory() as tmpdir:\n",
    "            ...\n",
    "\n",
    "    Upon exiting the context, the directory and everything contained\n",
    "    in it are removed.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, suffix=\"\", prefix=\"tmp\", dir=None):\n",
    "        self._closed = False\n",
    "        self.name = None  # Handle mkdtemp raising an exception\n",
    "        self.name = mkdtemp(suffix, prefix, dir)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"<{} {!r}>\".format(self.__class__.__name__, self.name)\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self.name\n",
    "\n",
    "    def cleanup(self, _warn=False):\n",
    "        if self.name and not self._closed:\n",
    "            try:\n",
    "                self._rmtree(self.name)\n",
    "            except (TypeError, AttributeError) as ex:\n",
    "                # Issue #10188: Emit a warning on stderr\n",
    "                # if the directory could not be cleaned\n",
    "                # up due to missing globals\n",
    "                if \"None\" not in str(ex):\n",
    "                    raise\n",
    "                print(\"ERROR: {!r} while cleaning up {!r}\".format(ex, self,),\n",
    "                      file=_sys.stderr)\n",
    "                return\n",
    "            self._closed = True\n",
    "            if _warn:\n",
    "                self._warn(\"Implicitly cleaning up {!r}\".format(self),\n",
    "                           ResourceWarning)\n",
    "\n",
    "    def __exit__(self, exc, value, tb):\n",
    "        self.cleanup()\n",
    "\n",
    "    def __del__(self):\n",
    "        # Issue a ResourceWarning if implicit cleanup needed\n",
    "        self.cleanup(_warn=True)\n",
    "\n",
    "    # XXX (ncoghlan): The following code attempts to make\n",
    "    # this class tolerant of the module nulling out process\n",
    "    # that happens during CPython interpreter shutdown\n",
    "    # Alas, it doesn't actually manage it. See issue #10188\n",
    "    _listdir = staticmethod(_os.listdir)\n",
    "    _path_join = staticmethod(_os.path.join)\n",
    "    _isdir = staticmethod(_os.path.isdir)\n",
    "    _islink = staticmethod(_os.path.islink)\n",
    "    _remove = staticmethod(_os.remove)\n",
    "    _rmdir = staticmethod(_os.rmdir)\n",
    "    _warn = _warnings.warn\n",
    "\n",
    "    def _rmtree(self, path):\n",
    "        # Essentially a stripped down version of shutil.rmtree.  We can't\n",
    "        # use globals because they may be None'ed out at shutdown.\n",
    "        for name in self._listdir(path):\n",
    "            fullname = self._path_join(path, name)\n",
    "            try:\n",
    "                isdir = self._isdir(fullname) and not self._islink(fullname)\n",
    "            except OSError:\n",
    "                isdir = False\n",
    "            if isdir:\n",
    "                self._rmtree(fullname)\n",
    "            else:\n",
    "                try:\n",
    "                    self._remove(fullname)\n",
    "                except OSError:\n",
    "                    pass\n",
    "        try:\n",
    "            self._rmdir(path)\n",
    "        except OSError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pi\n",
    "#from pyfits import writeto,getdata\n",
    "import sys\n",
    "import subprocess\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.cosmology import Planck15 as cosmo\n",
    "import astropy.units as u\n",
    "from astropy import constants as const\n",
    "from astropy.convolution import convolve,convolve_fft,Gaussian2DKernel\n",
    "\n",
    "\n",
    "def progressBar(name, value, endvalue, bar_length = 25, width = 20):\n",
    "    \n",
    "        percent = float(value) / endvalue\n",
    "        arrow = '-' * int(round(percent*bar_length) - 1) + '>'\n",
    "        spaces = ' ' * (bar_length - len(arrow))\n",
    "        sys.stdout.write(\"\\r{0: <{1}} : [{2}]{3}%\".format(name, width, arrow + spaces, int(round(percent*100))))\n",
    "        sys.stdout.flush()\n",
    "        if value == endvalue:        \n",
    "             sys.stdout.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "\n",
    "deadzone = 50\n",
    "save_stars = 'n'    #save the stars.dat file?\n",
    "raypix=0.4           #corresponds to rays per unlensed pixel in the IPM program\n",
    "ny=1000          #pixels of the magnification map\n",
    "yl=10               #half size of magnification map in einstein radii\n",
    "eps=0.02           #maximum flux-loss fraction\n",
    "halonumber = 20\n",
    "# ranges and bins of the linear histogram\n",
    "linran1 = 0\n",
    "linran2 = 100\n",
    "linbin = 2000\n",
    "# ranges and bins of the magnitude histogram\n",
    "magran1 = -10\n",
    "magran2 = 10\n",
    "magbin = 2000\n",
    "\n",
    "mbh = 30\n",
    "\n",
    "convolve_radii = [5,100,200] #radii in lightdays\n",
    "convolve_radii = np.array(convolve_radii)\n",
    "convolve_radii = (convolve_radii/365*u.lyr).to(u.pc) #convert to parsec\n",
    "\n",
    "\n",
    "subprocess.call(['gfortran','ipm_treecode.f90','-o', 'program.out','-ffixed-line-length-0','-w'])\n",
    "fortran_path = \"/users/sven/Documents/clustercode\"\n",
    "\n",
    "def einstein_radius(m,z1,z2):\n",
    "    val = np.sqrt(4*const.G*m*u.Msun*cosmo.angular_diameter_distance_z1z2(z1,z2)/((const.c)**2*cosmo.angular_diameter_distance(z1)*cosmo.angular_diameter_distance(z2)))\n",
    "    dimlessval = val.to(u.m/u.m)\n",
    "    return dimlessval.value\n",
    "\n",
    "def einstein_radius_mpc(m,z1,z2):\n",
    "    return cosmo.angular_diameter_distance(z2)*einstein_radius(m,z1,z2)\n",
    "\n",
    "def einstein_radius_lensplane(m,z1,z2):\n",
    "    return cosmo.angular_diameter_distance(z1)*einstein_radius(m,z1,z2)\n",
    "\n",
    "def pattern_size_lensplane(yl,m,z1,z2):\n",
    "    return (2*yl*einstein_radius_lensplane(m,z1,z2)).to(u.pc)\n",
    "\n",
    "def pixel_size_lensplane(ny,yl,m,z1,z2):\n",
    "    return (pattern_size_lensplane(yl,m,z1,z2)/ny).to(u.pc)\n",
    "\n",
    "def pattern_size(yl,m,z1,z2):\n",
    "    return (2*yl*einstein_radius_mpc(m,z1,z2)).to(u.pc)\n",
    "\n",
    "def pixel_size(ny,yl,m,z1,z2):\n",
    "    return (pattern_size(yl,m,z1,z2)/ny).to(u.pc)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def run_simulation(counter,qsoname,kappa,gamma,alpha,concentration,radius,z1,z2,blackholemass):\n",
    "    foldername = qsoname+'/'+str(alpha)+'_'+str(concentration)+'_'+str(radius.value)\n",
    "    if(counter==0):\n",
    "        os.mkdir(foldername)\n",
    "    with TemporaryDirectory(prefix=\"microlens_tmp_\") as tempdir:\n",
    "        clustermass = blackholemass*concentration\n",
    "        radius = radius/pixel_size_lensplane(ny,yl,clustermass,z1,z2)\n",
    "        radius = radius.value\n",
    "        #randsed=float( input('Please enter a random seed: ')) #random seed input\n",
    "        ks=kappa*alpha              #convergence in stars\n",
    "        kc=kappa*(1.-alpha)         #convergence in smooth matter\n",
    "        ys=2.*yl/(ny-1)             #size of pixel in image plane\n",
    "        f1=1./abs(1.-kappa-gamma)\n",
    "        f2=1./abs(1.-kappa+gamma)\n",
    "        sqrpix=np.sqrt(raypix)\n",
    "        fmax=max(f1,f2)\n",
    "        xl1,xl2=1.5*yl*f1, 1.5*yl*f2        #half size of shooting region\n",
    "        xl=1.5*yl*fmax\n",
    "        nsmin=3*ks**2/eps/abs((1.-kappa)**2-gamma**2)    #min number of stars\n",
    "        xmin=np.sqrt(pi*nsmin/ks)/2                     #min half side of stars region\n",
    "        xls=xl+xmin                                     #account for shooting region\n",
    "        xnl=abs(ks*(2*xls)*(2*xls)/pi)\n",
    "        nl=int(xnl)                                     #number of microlenses\n",
    "        nx1=np.int32(np.round(1.5*ny*f1*sqrpix))\n",
    "        nx2=np.int32(np.round(1.5*ny*f2*sqrpix))\n",
    "        nx=max(nx1,nx2)\n",
    "        thmag=1./(1-kappa-gamma)/(1-kappa+gamma)\n",
    "\n",
    "        #write the param.dat\n",
    "        with open(os.path.join(tempdir,'param.dat'),'w') as fil:\n",
    "            fil.write(str(yl)+' '+str(ny)+'\\n')\n",
    "            fil.write(str(xl)+' '+str(nx)+'\\n')\n",
    "            fil.write(str(ks)+' '+str(kc)+' '+str(gamma)+'\\n')\n",
    "            fil.write(str(1))\n",
    "            fil.flush()\n",
    "        #write the stars.dat and the testhalo.dat\n",
    "\n",
    "        clusternumber=int(nl) #Number of Microlenses\n",
    "        x1h=np.random.uniform(-xls,xls,clusternumber)\n",
    "        x2h=np.random.uniform(-xls,xls,clusternumber)\n",
    "        with open(os.path.join(tempdir,'stars.dat'),'w') as fil:\n",
    "            for i in range(clusternumber):\n",
    "                fil.write(str(x1h[i])+' '+str(x2h[i])+' '+str(1)+'\\n')\n",
    "            fil.flush()\n",
    "\n",
    "        starnumber = halonumber*concentration\n",
    "        x1s = np.random.normal(0,radius,starnumber)\n",
    "        x2s = np.random.normal(0,radius,starnumber)\n",
    "        with open(os.path.join(tempdir,'testhalo.dat'),'w') as fil:\n",
    "            for i in range(starnumber):\n",
    "                fil.write(str(x1s[i])+' '+str(x2s[i])+'\\n')\n",
    "            fil.flush()\n",
    "            \n",
    "        command = [\n",
    "            \"nice\", os.path.join(fortran_path,\"program.out\"), \"stars.dat\", \"pattern.dat\", \"param.dat\", str(halonumber), str(concentration)]\n",
    "        proc = subprocess.Popen(\n",
    "                command, stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n",
    "                cwd=tempdir)\n",
    "        outs, errs = proc.communicate()\n",
    "        if proc.returncode != 0:\n",
    "            print (proc.returncode)\n",
    "            if True:\n",
    "                outdir = os.path.join('crashes', \"nicaea_data_last_crash\")\n",
    "                if os.path.exists(outdir):\n",
    "                    shutil.rmtree(outdir)\n",
    "                shutil.copytree(tempdir, outdir)\n",
    "            if True:\n",
    "                print(\">>> stdout <<<\\n\", outs.decode(\"utf-8\"))\n",
    "                print(\">>> stderr <<<\\n\", errs.decode(\"utf-8\"))\n",
    "                raise subprocess.CalledProcessError(\n",
    "                    proc.returncode, \" \".join(command))\n",
    "            else:\n",
    "                return None\n",
    "            \n",
    "        result = createfits(os.path.join(tempdir,\"pattern.dat\"),ny)\n",
    "        convradii = ((convolve_radii/pixel_size(ny,yl,clustermass,z1,z2)).to(u.pc/u.pc)).value\n",
    "#         print(convradii)\n",
    "        fitsmap1 = result #convolve_fft(result,Gaussian2DKernel(convradii[1]))\n",
    "        fitsmap1 = fitsmap1+0.0000001\n",
    "        fitsmap2 = convolve_fft(result,Gaussian2DKernel(convradii[2]))\n",
    "        fitsmap2 = fitsmap2+0.0000001\n",
    "        fitsmap3 = fitsmap1/fitsmap2\n",
    "        fitsmaps = [fitsmap1,fitsmap2,fitsmap3]\n",
    "        for ii in range(3):\n",
    "#             print(\"Creating Histogram\", ii)\n",
    "            if(np.isnan(fitsmap1).any() or fitsmap1.any() <= 0.000001):\n",
    "                print(\"Error\")\n",
    "                sys.exit()\n",
    "            if(np.isnan(fitsmap2).any() or fitsmap2.any() <= 0.000001):\n",
    "                print(\"Error2\")\n",
    "                sys.exit()\n",
    "            if(np.isnan(fitsmap3).any() or fitsmap3.any() <= 0.000001):\n",
    "                print(\"Error3\")\n",
    "                sys.exit()\n",
    "            savename = foldername+'/'+str(ii)+'_'+str(counter)\n",
    "            create_histogram(savename,fitsmaps[ii],thmag)\n",
    "        return fitsmap1\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "def create_histogram(savename,fitsmap,thmag):\n",
    "#     fil = open(savename+'log','w')\n",
    "#     for i in range(ny):\n",
    "#         for j in range(ny):\n",
    "#             fil.write(str(fitsmap[i,j])+' ')\n",
    "#         fil.write('\\n')\n",
    "#     fil.close()\n",
    "    fitsmap = fitsmap[deadzone:ny-deadzone,deadzone:ny-deadzone]/thmag\n",
    "#     plt.imshow(fitsmap)\n",
    "#     plt.colorbar()\n",
    "#     plt.show()\n",
    "    fitsmap = np.ravel(fitsmap)\n",
    "    m = np.mean(fitsmap)\n",
    "#     print('creating linhist')\n",
    "    linhist,linedges = np.histogram(fitsmap, bins=linbin, range = (linran1,linran2))\n",
    "#     print('taking log')\n",
    "    fitsmap = -2.5*np.log10(fitsmap)\n",
    "#     print('creating maghist')\n",
    "    maghist,magedges = np.histogram(fitsmap, bins=magbin, range = (magran1,magran2))    \n",
    "    np.save(savename,[linhist,linedges,maghist,magedges])\n",
    "    \n",
    "def createfits(filein,size):\n",
    "    size=int(size)\n",
    "    a=np.zeros((size,size))\t  # Create a numpy square array of the right size\n",
    "    n=0\t\t\t  # Initialize counter\n",
    "    if (os.path.exists(filein)):\t\t# Check that input file exists\n",
    "        for line in open(filein, 'r'):\t# Loop over lines\n",
    "            i=int(n%size)\t\t\t# This is row number\n",
    "            j=int(n/size)\t\t\t# This is column number\n",
    "            a[j,i]=float(line)\t\t# Store data on array\n",
    "            n+=1\n",
    "        return a\n",
    "    else:\t\t\t  # If input file does not exist exit\n",
    "        print (\"File\",filein, \"does not exist\")\n",
    "\n",
    "\n",
    "def simulate_quasar(nsims,nprocs,alphas,concs,radii,qsoname,z1,z2,kappa,gamma):\n",
    "    exitflag = True\n",
    "    runcounter = 0\n",
    "    arglist = []\n",
    "    if not os.path.exists(qsoname):\n",
    "        os.mkdir(qsoname)\n",
    "    for alpha in alphas:\n",
    "        for concentration in concs:\n",
    "            for radius in radii:\n",
    "                for counter in range(nsims):\n",
    "                    arglist.append([counter,qsoname,kappa,gamma,alpha,concentration,radius,z1,z2,mbh])\n",
    "    length = len(arglist)\n",
    "    while(exitflag):\n",
    "        progressBar(qsoname,runcounter,length)\n",
    "        for i in range(nprocs):\n",
    "            if(runcounter+i<length):\n",
    "                job = mp.Process(target=run_simulation, args=arglist[runcounter+i])\n",
    "                job.start()\n",
    "            else:\n",
    "                exitflag=False\n",
    "        for i in range(nprocs):\n",
    "            if(runcounter+i<length):\n",
    "                job.join()\n",
    "                job.terminate()\n",
    "        runcounter = runcounter+nprocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsims = 20\n",
    "nprocs = 100\n",
    "\n",
    "data = open('lenses-milib_A.dat','r')\n",
    "lenses = data.readlines()\n",
    "data.close()\n",
    "nl=0\n",
    "for lens in lenses:\n",
    "    [name,kappa,gamma,ds,dl,dls,temp0,temp1] = lens.split()\n",
    "    kappa = float(kappa)\n",
    "    gamma = float(gamma)\n",
    "    nl=nl+1\n",
    "    \n",
    "lens = lenses[0]\n",
    "[qsoname,kappa,gamma,ds,dl,dls,temp0,temp1] = lens.split()\n",
    "z1 = 0.4\n",
    "z2 = 0.9\n",
    "kappa = float(kappa)\n",
    "gamma = float(gamma)\n",
    "qsoname = qsoname.replace(\" \",\"\")\n",
    "alphas = [0.1,0.2,0.5,0.8]\n",
    "radii = [0.2]*u.pc\n",
    "concs = [300]\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "rxj1131a             : [>                        ]0%"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    simulate_quasar(nsims,nprocs,alphas,concs,radii,qsoname,z1,z2,kappa,gamma)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.703703703703704\n"
     ]
    }
   ],
   "source": [
    "print(1./(1-kappa-gamma)/(1-kappa+gamma))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
